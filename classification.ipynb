{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed73e93",
   "metadata": {},
   "source": [
    "# CLASSIFICATION EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e17652",
   "metadata": {},
   "source": [
    "So far, you've only created regression models. That is, you created models that produced floating-point predictions, such as, \"houses in this neighborhood costs N thousand dollars.\" In this Colab, you'll create and evaluate a binary classification model. That is, you'll create a model that answers a binary question. In this exercise, the binary question will be, \"Are houses in this neighborhood above a certain price?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591357cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "# tf.keras.backend.set_floatx('float32')\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8956dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d2aaa",
   "metadata": {},
   "source": [
    "## Normalize Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4bc9e",
   "metadata": {},
   "source": [
    "When creating a model with multiple features, the values of each feature should cover roughly the same range. For example, if one feature's range spans 500 to 100,000 and another feature's range spans 2 to 12, then the model will be difficult or impossible to train. Therefore, you should normalize features in a multi-feature model.\n",
    "\n",
    "The following code cell normalizes datasets by converting each raw value (including the label) to its Z-score. A Z-score is the number of standard deviations from the mean for a particular raw value. For example, consider a feature having the following characteristics:\n",
    "\n",
    " -- The mean is 60.\n",
    " \n",
    " --The standard deviation is 10.\n",
    " \n",
    " The raw value 75 would have a Z-score of +1.5:\n",
    " \n",
    "       Z-score = (75 - 60) / 10 = +1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f83439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso no vamos a escalar los valores como hemos hecho en ejercicios anteriores\n",
    "#train_df['median_house_value'] /= 1000\n",
    "#test_df['median_house_value'] /= 1000\n",
    "\n",
    "# en este caso vamos a NORMALIZAR los datos creando un panda nuevo con los Z-Scores:\n",
    "train_df_mean = train_df.mean()\n",
    "train_df_std = train_df.std()\n",
    "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
    "train_df_norm.head()\n",
    "\n",
    "test_df_mean = test_df.mean()\n",
    "test_df_std  = test_df.std()\n",
    "test_df_norm = (test_df - test_df_mean)/test_df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064de10",
   "metadata": {},
   "source": [
    "Ahora, examninando algunos de los valores del data set normalizado, se puede ver todos los Z-Scores estan entre +-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185a7e9",
   "metadata": {},
   "source": [
    "### Task 1: Create a binary label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d887b",
   "metadata": {},
   "source": [
    "Your task is to create a new column named median_house_value_is_high in both the training set and the test set . If the median_house_value is higher than a certain arbitrary value (defined by threshold), then set median_house_value_is_high to 1. Otherwise, set median_house_value_is_high to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879bd942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3003    1.0\n",
       "3620    0.0\n",
       "3108    1.0\n",
       "5842    0.0\n",
       "421     0.0\n",
       "         ..\n",
       "4155    0.0\n",
       "2725    0.0\n",
       "10776   0.0\n",
       "14587   0.0\n",
       "5794    0.0\n",
       "Name: median_house_value_is_high, Length: 800, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 265000 # This is the 75th percentile for median house values.\n",
    "\n",
    "train_df_norm['median_house_value_is_high'] = (train_df['median_house_value'] > threshold).astype(float)\n",
    "test_df_norm['median_house_value_is_high'] = (test_df['median_house_value'] > threshold).astype(float)\n",
    "train_df_norm[\"median_house_value_is_high\"].head(800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66d411",
   "metadata": {},
   "source": [
    "### Represent features in feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c486",
   "metadata": {},
   "source": [
    "This code cell specifies the features that you'll ultimately train the model on and how each of those features will be represented. The transformations (collected in feature_layer) don't actually get applied until you pass a DataFrame to it, which will happen when we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbd74cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17000, 2), dtype=float32, numpy=\n",
       "array([[ 5.021822  ,  0.1143769 ],\n",
       "       [-0.534169  , -0.40444303],\n",
       "       [ 1.6628206 , -0.15397824],\n",
       "       ...,\n",
       "       [ 0.34175494,  0.1694241 ],\n",
       "       [-0.50670797, -0.49618837],\n",
       "       [-0.10391082, -0.21131907]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_column = []\n",
    "\n",
    "media_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "feature_column.append(media_income)\n",
    "\n",
    "tr = tf.feature_column.numeric_column(\"total_rooms\")\n",
    "feature_column.append(tr)\n",
    "\n",
    "feature_layer = layers.DenseFeatures(feature_column)\n",
    "\n",
    "# Print the first 3 and last 3 rows of the feature_layer's output when applied\n",
    "# to train_df_norm:\n",
    "feature_layer(dict(train_df_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5b46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all functions created succesfully\n"
     ]
    }
   ],
   "source": [
    "#crear funciones que crean el modelo y lo entrenan. ademas otro que hace la gr√°fica\n",
    "\n",
    "def build_model(learning_rate, feature_layer, my_metrics):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(feature_layer)\n",
    "    \n",
    "    # Funnel the regression value through a sigmoid function.\n",
    "    model.add(tf.keras.layers.Dense(units = 1,\n",
    "                                   input_shape=(1,),\n",
    "                                   activation=tf.sigmoid))\n",
    "    \n",
    "    # Call the compile method to construct the layers into a model that\n",
    "    # TensorFlow can execute.  Notice that we're using a different loss\n",
    "    # function for classification than for regression. \n",
    "    # ademas se ve que le metemos las metrics que queramos\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=learning_rate),\n",
    "                 loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=my_metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, df, epochs, label_name, batch_size=None, shuffle=True):\n",
    "    \n",
    "    # The x parameter of tf.keras.Model.fit can be a list of arrays, where\n",
    "    # each array contains the data for one feature.  Here, we're passing\n",
    "    # every column in the dataset. Note that the feature_layer will filter\n",
    "    # away most of those columns, leaving only the desired columns and their\n",
    "    # representations as features.\n",
    "    \n",
    "    features = {name:np.array(value) for name, value in df.items()}\n",
    "    label = np.array(features.pop(label_name))\n",
    "    history = model.fit(x=features, y=label, batch_size = batch_size, epochs=epochs, shuffle= shuffle)\n",
    "    \n",
    "    epochs = history.epoch\n",
    "    \n",
    "    # Isolate the classification metric for each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    \n",
    "    return epochs, hist\n",
    "\n",
    " \n",
    "\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    \n",
    "    # esto hace que analice todos los metrics que le metemos sea accuracy, precision, recall o los que sean \n",
    "    for m in list_of_metrics:\n",
    "        \n",
    "        x=hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "        \n",
    "    plt.legend()\n",
    "    \n",
    "print(\"all functions created succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e4fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "170/170 [==============================] - 2s 8ms/step - loss: 0.7238 - accuracy: 0.2996\n",
      "Epoch 2/30\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.3439\n",
      "Epoch 3/30\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.5548 - accuracy: 0.4925\n",
      "Epoch 4/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4977 - accuracy: 0.6712\n",
      "Epoch 5/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4565 - accuracy: 0.7487\n",
      "Epoch 6/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.7749\n",
      "Epoch 7/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4164 - accuracy: 0.7948\n",
      "Epoch 8/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.4092 - accuracy: 0.7966\n",
      "Epoch 9/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.4028 - accuracy: 0.8045\n",
      "Epoch 10/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.8043\n",
      "Epoch 11/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3924 - accuracy: 0.8088\n",
      "Epoch 12/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.8036\n",
      "Epoch 13/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3974 - accuracy: 0.8093\n",
      "Epoch 14/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3910 - accuracy: 0.8107\n",
      "Epoch 15/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8071\n",
      "Epoch 16/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8047\n",
      "Epoch 17/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8097\n",
      "Epoch 18/30\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.3932 - accuracy: 0.8079\n",
      "Epoch 19/30\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8024\n",
      "Epoch 20/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8072\n",
      "Epoch 21/30\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.3995 - accuracy: 0.8098\n",
      "Epoch 22/30\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8129\n",
      "Epoch 23/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8094\n",
      "Epoch 24/30\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3943 - accuracy: 0.8096\n",
      "Epoch 25/30\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.3939 - accuracy: 0.8101\n",
      "Epoch 26/30\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.3987 - accuracy: 0.8079\n",
      "Epoch 27/30\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.3884 - accuracy: 0.8112\n",
      "Epoch 28/30\n",
      "170/170 [==============================] - 2s 10ms/step - loss: 0.3966 - accuracy: 0.8096\n",
      "Epoch 29/30\n",
      "170/170 [==============================] - 1s 7ms/step - loss: 0.3966 - accuracy: 0.8087\n",
      "Epoch 30/30\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.8104\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "label_name = \"median_house_value_is_high\"\n",
    "threshold = 0.35\n",
    "\n",
    "# Establish the metrics the model will measure.\n",
    "METRICS= [tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=threshold)]\n",
    "\n",
    "my_model = build_model(learning_rate, feature_layer, METRICS)\n",
    "\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs, \n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot a graph of the metric(s) vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy'] \n",
    "\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedf978",
   "metadata": {},
   "source": [
    "Accuracy should gradually improve during training (until it can no more)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b09e0f",
   "metadata": {},
   "source": [
    "#### Now evaluate the model against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dda3cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4069024920463562, 0.8009999990463257]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "label = np.array(features.pop(label_name))\n",
    "\n",
    "my_model.evaluate(x = features, y = label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ab728",
   "metadata": {},
   "source": [
    "Parece un buen modelo pero, en realidad un modelo que siempre predijera que \"median_house_value_is_high\" es False tendria una accuracy del 75% comparado con el 80% de este. entonces no es que nuestro modelo sea muy util.\n",
    "\n",
    "Relying only in accuracy, can be a poor way to judge a classification model. Now let's modify our model to measure precision and recall too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be25903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\n        self.build(y_pred, y_true)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:317 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1159 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1257 map_structure_with_tuple_paths_up_to\n        results = [\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1258 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1161 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3494 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <module 'tensorflow.keras.metrics' from '/home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/keras/metrics/__init__.py'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b03df830df02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Train the model on the training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m epochs, hist = train_model(my_model, train_df_norm, epochs, \n\u001b[0m\u001b[1;32m     25\u001b[0m                            label_name, batch_size)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-be40be99f21a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, df, epochs, label_name, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:758 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\n        self.build(y_pred, y_true)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:317 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1159 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1257 map_structure_with_tuple_paths_up_to\n        results = [\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1258 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1161 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3494 get\n        raise ValueError(\n\n    ValueError: Could not interpret metric function identifier: <module 'tensorflow.keras.metrics' from '/home/candel/anaconda3/lib/python3.8/site-packages/tensorflow/keras/metrics/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "classification_threshold = 0.65\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# Antes habiamos a√±adido solo accuracy, ahora tenemos que a√±adir precision y recall\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy', \n",
    "                                      threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
    "                                 name='precision' \n",
    "                                 ),\n",
    "      tf.keras.metrics.Recall(thresholds=classification_threshold, name=\"recall\"),\n",
    "    \n",
    "      tf.keras.metrics\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = build_model(learning_rate, feature_layer, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs, \n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', 'precision', 'recall'] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2d553",
   "metadata": {},
   "source": [
    "Ahora puedes hacer un metric que los junte a todos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a981e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_8:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'median_house_value': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "170/170 [==============================] - 2s 6ms/step - loss: 0.6567 - auc: 0.7461\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.5874 - auc: 0.7766\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.5346 - auc: 0.7880\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4903 - auc: 0.8007\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4683 - auc: 0.8030\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4360 - auc: 0.8223\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.4168 - auc: 0.8299\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.4079 - auc: 0.8325\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.4009 - auc: 0.8324\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.4034 - auc: 0.8337\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.3942 - auc: 0.8393\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3940 - auc: 0.8410\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 0.3968 - auc: 0.8339\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3937 - auc: 0.8408\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3958 - auc: 0.8387\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3955 - auc: 0.8345\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3985 - auc: 0.8371\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3915 - auc: 0.8388\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3958 - auc: 0.8375\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.3917 - auc: 0.8394\n"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "classification_threshold = 0.65\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# Antes habiamos a√±adido solo accuracy, ahora tenemos que a√±adir precision y recall\n",
    "METRICS = [\n",
    "      tf.keras.metrics.AUC(num_thresholds=100, name='auc')\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = build_model(learning_rate, feature_layer, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs, \n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = [\"auc\"] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721ff14",
   "metadata": {},
   "source": [
    "Podemos ver que el auc es el mismo que el acuraccy del codigo anterior y es mas comodo y se ve mas claro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
